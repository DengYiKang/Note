对于cross-device场景，比如mobile device的情况，client的数量非常多，那么肯定是需要采样的，那么如何指定采样方案？

很多的FL算法都是同步算法，意味着服务器需要等待所有client本地迭代完才能执行全局更新，那么存在短板效应，如何指定相应的策略？

对于基于梯度的CFL来说，因为二分，对于每个类来说只有全局接近了平衡点才进行二分，那么整体的训练时间将会拉到特别长，如何解决训练时间过长的问题？也存在超参的设定问题，能否通过meta learning来学习？能否通过一轮平衡直接划分出多个，而不是循环二分。如果一轮平衡，那么簇数K如何确定？有两种情况，K偏大，那么需要别的手段进行平衡，例如meta learning学习重加权；K偏小，那么可能存在过拟合，应该在聚类函数中添加簇中最小数的限制。

在**Decoupling Representation and Classifier for Long-Tailed Recognition, ICLR 2020**这篇文章中，将长尾分类模型的学习分成了两步，第一步，不做任何再均衡，而是直接像传统的分类一样，利用原始的数据学习一个分类模型（包含特征提取的backbone+一个全连接分类器）；第二步，将第一步学习的模型中的特征提取backbone的参数固定，然后单独接上一个分类器，对分配器进行class-balanced sampling学习。

那么是否能用到FL中？对于分类任务的FL，首先对特征提取的模型进行训练，方式是最基本的联邦平均，当全局接近稳定后（或者特征提取的模型接近稳定后），将特征提取模型的参数固定，然后根据分类器的梯度进行聚类，成k个簇，然后对这k个簇进行重加权重新训练（这一步可以使用另一个网络来学习权重，见Meta-Weight-Net）。



